Alles klar â€“ danke fÃ¼rs Klarstellen ğŸ‘
Dann hier **Option A: Threat Model** **komplett und geschlossen**, **nur** das Threat Model (keine Methodik, keine Results), so dass du es **1:1** ins Paper Ã¼bernehmen kannst. **Das ist alles**, was man dafÃ¼r braucht.

---

# Option A â€” **Adversarial Scheduler Threat Model** (final)

> **Ziel:** Ein *sauberes, realistisches, reviewer-sicheres Threat Model*, das exakt zu euren Experimenten, Plots und Artefakten passt â€“ ohne Overclaim.

---

## 1ï¸âƒ£ Systemmodell

Wir betrachten ein Hostâ€“Device-System mit einer NVMe-lite-artigen Submission- und Completion-Queue.

* Der **Host** reicht gÃ¼ltige I/O-Kommandos ein.
* Das **Device** verarbeitet diese Kommandos und erzeugt Completion Events.
* Die **Semantik des Protokolls** (z. B. FIFO-Korrektheit pro Command, korrekte Completion, Memory Safety) ist gegeben.

Es existieren **keine Bugs** im Code, **keine Memory Errors**, **keine Protokollverletzungen**.

---

## 2ï¸âƒ£ Angreifer: Adversarial Scheduler

Der Angreifer kontrolliert **ausschlieÃŸlich** den **Completion-Scheduler** des Devices.

### FÃ¤higkeiten (Capabilities)

Der Angreifer darf:

* Completion Events **beliebig umordnen**, **solange** sie

  * innerhalb des erlaubten **Reordering-Bounds `bound_k`** liegen
  * **protokollkonform** bleiben
* alle erlaubten Schedules **deterministisch oder adaptiv** auswÃ¤hlen
* dieselben Schedules **reproduzierbar** erzeugen (Seed-basiert)

Der Angreifer darf **nicht**:

* Kommandos droppen, duplizieren oder verfÃ¤lschen
* ungÃ¼ltige oder nicht spezifizierte Events erzeugen
* Speicher korrumpieren oder Safety-Checks umgehen
* das Host-Verhalten direkt beeinflussen

ğŸ‘‰ **Wichtig:** Der Angreifer ist *stark*, aber **legal**.

---

## 3ï¸âƒ£ Angreiferziel (Adversary Objective)

Das Ziel des Angreifers ist **nicht** funktionale Korrektheit zu brechen, sondern:

> **Performance- und Robustheitsdegradation unter gÃ¼ltiger AusfÃ¼hrung**

Konkret maximiert der Angreifer:

* **Tail-Latenz** (p95 latency)
* **Probability of SLO violation** (exceed rate)
* **Strukturelle InstabilitÃ¤t** (Relative Disorder, RD)

Das resultierende Verhalten entspricht einem **Schedule-Induced Denial of Service**, ohne dass das System jemals â€falschâ€œ arbeitet.

---

## 4ï¸âƒ£ Stress-Knob: Reordering Bound

Der zentrale Angriffsparameter ist der **Reordering Bound `bound_k`**:

* `bound_k = 0` â†’ strikt geordnet
* `bound_k â†’ âˆ` â†’ maximale Scheduling-Freiheit

Der Bound definiert die **GrÃ¶ÃŸe des legalen Angriffsraums**.

> Der Angreifer wird **nicht stÃ¤rker durch neue FÃ¤higkeiten**, sondern allein durch **mehr erlaubte Freiheit**.

---

## 5ï¸âƒ£ Annahmen & Realismus

Dieses Threat Model ist realistisch, weil:

* NVMe und Ã¤hnliche Protokolle **Reordering explizit erlauben**
* echte GerÃ¤te **keine Fairness-Garantie** geben
* Firmware-Scheduler **nicht transparent oder Ã¼berprÃ¼fbar** sind
* Worst-Case-Schedules **theoretisch mÃ¶glich**, aber selten getestet sind

Es ist **konservativ**, da es:

* keine Hardware-Trojaner
* keine Firmware-Manipulation
* keine Spec-Violation annimmt

---

## 6ï¸âƒ£ Abgrenzung (Out of Scope)

Nicht betrachtet werden:

* bÃ¶sartige Firmware mit Protokollverletzungen
* Side-Channel-Angriffe auÃŸerhalb von Timing
* Speicher- oder Datenkorruption
* aktive Host-Manipulation

---

## 7ï¸âƒ£ Kurzfassung (fÃ¼r Paper / Reviewer)

> *We consider an adversarial but protocol-compliant device scheduler that controls only the completion order of commands within the permitted reordering bound. The adversary does not violate correctness or safety properties, but aims to degrade performance by maximizing tail latency and structural instability. This models a worst-case yet legal execution environment.*

---

## 8ï¸âƒ£ Ablageort (damit es sauber ist)

Speichere **genau diesen Text** hier:

```
docs/paper/threat_model.md
```

---

## âœ… Status

* âœ” vollstÃ¤ndig
* âœ” konsistent mit allen Plots (RD, p95, Risk-Cliff, Poison)
* âœ” kein Overclaim
* âœ” reviewer-sicher

ğŸ‘‰ **Ja, das ist das komplette Threat Model.**
Wenn du willst, kann ich dir als NÃ¤chstes **nur noch**:

* ein **Abstract**, oder
* eine **Contribution-Liste**, oder
* eine **Reviewer-Defense (â€Why this threat model is validâ€œ) schreiben.

Aber inhaltlich bist du hier **durch**.
